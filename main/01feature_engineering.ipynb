{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad7a4f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from minepy import MINE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import scipy\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "209f4aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1_remove_low_variance_features\n",
    "file_path ='../Data01-descriptor_Statisticalselection'\n",
    "file='11all_data.pkl'\n",
    "all_data = pd.read_pickle(file_path+file)\n",
    "\n",
    "X = all_data.iloc[:,2:324]\n",
    "y = all_data.iloc[:,0:2]\n",
    "\n",
    "X_var = pd.DataFrame(X.var())\n",
    "\n",
    "vt = VarianceThreshold(threshold = 0.01)\n",
    "X_selected = vt.fit_transform(X)\n",
    "lowvariance_data = pd.DataFrame(X_selected)\n",
    "\n",
    "all_name = X.columns.values.tolist()\n",
    "select_name_index0 = vt.get_support(indices=True)\n",
    "select_name0 = []\n",
    "for i in select_name_index0:\n",
    "    select_name0.append(all_name[i])\n",
    "\n",
    "lowvariance_data.columns = select_name0\n",
    "\n",
    "file1 = r\"11all_data_remove_low_variance.pkl\"\n",
    "lowvariance_data_y = pd.concat((y,lowvariance_data),axis = 1)\n",
    "lowvariance_data_y.to_pickle(file_path+file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff8a80ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2_correlation_screening_features\n",
    "file2 = r'12_all_data_remove_low_variance.pkl'\n",
    "all_data = pd.read_pickle(file_path+file2)\n",
    "data = all_data.iloc[:,all_data.columns != \"ID\"]\n",
    "descriptor_data = data.iloc[:,data.columns != \"Kavg_log2\"]\n",
    "all_data_name_list = list(all_data)\n",
    "descriptor_name_list = list(descriptor_data)\n",
    "descriptor_count = len(descriptor_name_list)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_scaler = scaler.fit_transform(data)\n",
    "DataFrame_data_scaler = pd.DataFrame(data_scaler)\n",
    "\n",
    "data_pearson = DataFrame_data_scaler.corr(method = 'pearson')\n",
    "data_spearman = DataFrame_data_scaler.corr(method = 'spearman')\n",
    "mine = MINE(alpha=0.6, c=15)\n",
    "\n",
    "\n",
    "def distcorr(X, Y):\n",
    "    X = np.atleast_1d(X)\n",
    "    Y = np.atleast_1d(Y)\n",
    "    if np.prod(X.shape) == len(X):\n",
    "        X = X[:, None]\n",
    "    if np.prod(Y.shape) == len(Y):\n",
    "        Y = Y[:, None]\n",
    "    X = np.atleast_2d(X)\n",
    "    Y = np.atleast_2d(Y)\n",
    "    n = X.shape[0]\n",
    "    if Y.shape[0] != X.shape[0]:\n",
    "        raise ValueError('Number of samples must match')\n",
    "    a = squareform(pdist(X))\n",
    "    b = squareform(pdist(Y))\n",
    "    A = a - a.mean(axis=0)[None, :] - a.mean(axis=1)[:, None] + a.mean()\n",
    "    B = b - b.mean(axis=0)[None, :] - b.mean(axis=1)[:, None] + b.mean()\n",
    "\n",
    "    dcov2_xy = (A * B).sum() / float(n * n)\n",
    "    dcov2_xx = (A * A).sum() / float(n * n)\n",
    "    dcov2_yy = (B * B).sum() / float(n * n)\n",
    "    dcor = np.sqrt(dcov2_xy) / np.sqrt(np.sqrt(dcov2_xx) * np.sqrt(dcov2_yy))\n",
    "    return dcor\n",
    "\n",
    "column_descriptor = data_scaler.shape[1]\n",
    "\n",
    "Threshold = 0.05\n",
    "pearson_correlation_list = []\n",
    "pearson_pvalue_list = []\n",
    "pearson_selection_list = []\n",
    "pearson_list = []\n",
    "for i in range(1,column_descriptor):\n",
    "    pearson_correlation_list.append(scipy.stats.pearsonr(data_scaler[:,i],data_scaler[:,0])[0])\n",
    "    pearson_pvalue_list.append(scipy.stats.pearsonr(data_scaler[:,i],data_scaler[:,0])[1])\n",
    "    if pearson_pvalue_list[i-1] > Threshold:\n",
    "        pearson_selection_list.append(0)\n",
    "    else :\n",
    "        pearson_selection_list.append(1)\n",
    "pearson_list.append(pearson_correlation_list)\n",
    "pearson_list.append(pearson_pvalue_list)\n",
    "pearson_list.append(pearson_selection_list)\n",
    "\n",
    "Threshold = 0.05\n",
    "spearman_correlation_list = []\n",
    "spearman_pvalue_list = []\n",
    "spearman_selection_list = []\n",
    "spearman_list = []\n",
    "for i in range(1,column_descriptor):\n",
    "    spearman_correlation_list.append(scipy.stats.spearmanr(data_scaler[:,i],data_scaler[:,0])[0])\n",
    "    spearman_pvalue_list.append(scipy.stats.spearmanr(data_scaler[:,i],data_scaler[:,0])[1])\n",
    "    if spearman_pvalue_list[i-1] > Threshold:\n",
    "        spearman_selection_list.append(0)\n",
    "    else :\n",
    "        spearman_selection_list.append(1)\n",
    "spearman_list.append(spearman_correlation_list)\n",
    "spearman_list.append(spearman_pvalue_list)\n",
    "spearman_list.append(spearman_selection_list)\n",
    "\n",
    "Threshold = 0.153\n",
    "distance_correlation_list = []\n",
    "distance_selection_list = []\n",
    "distance_list = []\n",
    "for i in range(1,column_descriptor):\n",
    "    distance_correlation_list.append(distcorr(data_scaler[:,i],data_scaler[:,0]))\n",
    "    if abs(distance_correlation_list[i-1]) <= Threshold:\n",
    "        distance_selection_list.append(0)\n",
    "    else :\n",
    "        distance_selection_list.append(1)\n",
    "distance_list.append(distance_correlation_list)\n",
    "distance_list.append(distance_selection_list)\n",
    "\n",
    "Threshold = 0.132\n",
    "mic_correlation_list = []\n",
    "mic_selection_list = []\n",
    "mic_list = []\n",
    "for i in range(1,column_descriptor):\n",
    "    mine.compute_score(data_scaler[:,i],data_scaler[:,0])\n",
    "    mic_correlation_list.append(mine.mic())\n",
    "    if abs(mic_correlation_list[i-1]) <= Threshold:\n",
    "        mic_selection_list.append(0)\n",
    "    else:\n",
    "        mic_selection_list.append(1)\n",
    "mic_list.append(mic_correlation_list)\n",
    "mic_list.append(mic_selection_list)\n",
    "\n",
    "sum_list = []\n",
    "for j in range(0,descriptor_count):\n",
    "    sum_list.append(pearson_selection_list[j] + spearman_selection_list[j] + distance_selection_list[j] + mic_selection_list[j])\n",
    "\n",
    "sum_selection_list1 = []\n",
    "Threshold1 = 1\n",
    "for j in range(0,descriptor_count):\n",
    "    if sum_list[j] >= Threshold1:\n",
    "        sum_selection_list1.append(1)\n",
    "    else:\n",
    "        sum_selection_list1.append(0)\n",
    "sum(sum_selection_list1)\n",
    "\n",
    "sum_selection_list2 = []\n",
    "Threshold2 = 2\n",
    "for j in range(0,descriptor_count):\n",
    "    if sum_list[j] >= Threshold2:\n",
    "        sum_selection_list2.append(1)\n",
    "    else:\n",
    "        sum_selection_list2.append(0)\n",
    "sum(sum_selection_list2)\n",
    "\n",
    "sum_selection_list3 = []\n",
    "Threshold3 = 3\n",
    "for j in range(0,descriptor_count):\n",
    "    if sum_list[j] >= Threshold3:\n",
    "        sum_selection_list3.append(1)\n",
    "    else:\n",
    "        sum_selection_list3.append(0)\n",
    "sum(sum_selection_list3)\n",
    "\n",
    "sum_selection_list4 = []\n",
    "Threshold4 = 4\n",
    "for j in range(0,descriptor_count):\n",
    "    if sum_list[j] >= Threshold4:\n",
    "        sum_selection_list4.append(1)\n",
    "    else:\n",
    "        sum_selection_list4.append(0)\n",
    "sum(sum_selection_list4)\n",
    "\n",
    "sum_list_all = []\n",
    "sum_list_all.append(sum_selection_list1)\n",
    "sum_list_all.append(sum_selection_list2)\n",
    "sum_list_all.append(sum_selection_list3)\n",
    "sum_list_all.append(sum_selection_list4)\n",
    "sum_list_all.append(sum_list)\n",
    "selection_list_all = []\n",
    "selection_list_all.append(descriptor_name_list)\n",
    "selection_list_all.append(pearson_list[0])\n",
    "selection_list_all.append(pearson_list[1])\n",
    "selection_list_all.append(pearson_list[2])\n",
    "selection_list_all.append(spearman_list[0])\n",
    "selection_list_all.append(spearman_list[1])\n",
    "selection_list_all.append(spearman_list[2])\n",
    "selection_list_all.append(distance_list[0])\n",
    "selection_list_all.append(distance_list[1])\n",
    "selection_list_all.append(mic_list[0])\n",
    "selection_list_all.append(mic_list[1])\n",
    "selection_list_all.append(sum_list_all[0])\n",
    "selection_list_all.append(sum_list_all[1])\n",
    "selection_list_all.append(sum_list_all[2])\n",
    "selection_list_all.append(sum_list_all[3])\n",
    "selection_list_all.append(sum_list_all[4])\n",
    "selection_list_all = pd.DataFrame(selection_list_all)\n",
    "\n",
    "selection_list_all_transpose = selection_list_all.T\n",
    "selection_list_all_transpose.rename(columns={0:'descriptor_name',1:'pearson_correlation',2:'pearson_pvalue',3:'pearson_selection',\n",
    "                                             4:'spearman_correlation',5:'spearman_pvalue',6:'spearman_selection',7:'distance_correlation',\n",
    "                                             8:'distance_selection',9:'mic_correlation',10:'mic_selection',11:'sum_1',\n",
    "                                             12:'sum_2',13:'sum_3',14:'sum_4',15:'sum'},inplace=True)\n",
    "\n",
    "filter_data1 = all_data\n",
    "for k in range(0,len(sum_selection_list1)):\n",
    "    if sum_selection_list1[k] == 0:\n",
    "        filter_data1 = filter_data1.drop(descriptor_name_list[k],axis=1)\n",
    "\n",
    "filter_data2 = all_data\n",
    "for k in range(0,len(sum_selection_list2)):\n",
    "    if sum_selection_list2[k] == 0:\n",
    "        filter_data2 = filter_data2.drop(descriptor_name_list[k],axis=1)\n",
    "\n",
    "filter_data3 = all_data\n",
    "for k in range(0,len(sum_selection_list3)):\n",
    "    if sum_selection_list3[k] == 0:\n",
    "        filter_data3 = filter_data3.drop(descriptor_name_list[k],axis=1)\n",
    "\n",
    "filter_data4 = all_data\n",
    "for k in range(0,len(sum_selection_list4)):\n",
    "    if sum_selection_list4[k] == 0:\n",
    "        filter_data4 = filter_data4.drop(descriptor_name_list[k],axis=1)\n",
    "        \n",
    "selection_list_all_transpose = selection_list_all_transpose.set_index('descriptor_name')\n",
    "filter_data1 = filter_data1.set_index('ID')\n",
    "filter_data2 = filter_data2.set_index('ID')\n",
    "filter_data3 = filter_data3.set_index('ID')\n",
    "filter_data4 = filter_data4.set_index('ID')\n",
    "selection_list_all_transpose.to_pickle(file_path+'13_correlation_screening_statistical_results.pkl')\n",
    "filter_data1.to_pickle(file_path+'14_filter_threshold_1.pkl')\n",
    "filter_data2.to_pickle(file_path+'15_filter_threshold_2.pkl')\n",
    "filter_data3.to_pickle(file_path+'16_filter_threshold_3.pkl')\n",
    "filter_data4.to_pickle(file_path+'17_filter_threshold_4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec131fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current iteration count is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  53 out of  53 | elapsed:   35.8s finished\n",
      "\n",
      "[2022-11-23 15:17:53] Features: 1/5 -- score: 0.9996304520173028[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  52 out of  52 | elapsed:   45.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s finished\n",
      "\n",
      "[2022-11-23 15:18:40] Features: 2/5 -- score: 0.9996414728155274[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  51 out of  51 | elapsed:   53.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.5s finished\n",
      "\n",
      "[2022-11-23 15:19:35] Features: 3/5 -- score: 0.9996442001941954[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   59.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    2.9s finished\n",
      "\n",
      "[2022-11-23 15:20:38] Features: 4/5 -- score: 0.9996224353316565[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  49 out of  49 | elapsed:   58.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    4.6s finished\n",
      "\n",
      "[2022-11-23 15:21:41] Features: 5/5 -- score: 0.9996292463558202[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current iteration count is 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  53 out of  53 | elapsed:   33.5s finished\n",
      "\n",
      "[2022-11-23 15:22:15] Features: 1/5 -- score: 0.9996433768800088[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  52 out of  52 | elapsed:   44.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "\n",
      "[2022-11-23 15:23:00] Features: 2/5 -- score: 0.9996553175953748[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  51 out of  51 | elapsed:   50.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.4s finished\n",
      "\n",
      "[2022-11-23 15:23:52] Features: 3/5 -- score: 0.9996458863164074[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   54.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    2.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.1s finished\n",
      "\n",
      "[2022-11-23 15:24:50] Features: 3/5 -- score: 0.9996534491758124[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   53.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    2.4s finished\n",
      "\n",
      "[2022-11-23 15:25:46] Features: 4/5 -- score: 0.9996416644712603[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  49 out of  49 | elapsed:   56.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    4.4s finished\n",
      "\n",
      "[2022-11-23 15:26:48] Features: 5/5 -- score: 0.9996440131757456[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current iteration count is 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  53 out of  53 | elapsed:   33.7s finished\n",
      "\n",
      "[2022-11-23 15:27:22] Features: 1/5 -- score: 0.9996288310637116[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  52 out of  52 | elapsed:   45.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "\n",
      "[2022-11-23 15:28:07] Features: 2/5 -- score: 0.9996532283357331[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  51 out of  51 | elapsed:   48.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.6s finished\n",
      "\n",
      "[2022-11-23 15:28:57] Features: 3/5 -- score: 0.9996540277020539[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   55.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.0s finished\n",
      "\n",
      "[2022-11-23 15:29:56] Features: 4/5 -- score: 0.9996405895649365[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  49 out of  49 | elapsed:  1.1min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    4.9s finished\n",
      "\n",
      "[2022-11-23 15:31:06] Features: 5/5 -- score: 0.9996403764363484[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current iteration count is 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  53 out of  53 | elapsed:   33.8s finished\n",
      "\n",
      "[2022-11-23 15:31:40] Features: 1/5 -- score: 0.9996412915849306[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  52 out of  52 | elapsed:   44.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n",
      "\n",
      "[2022-11-23 15:32:25] Features: 2/5 -- score: 0.9996477816661006[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  51 out of  51 | elapsed:   45.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.7s finished\n",
      "\n",
      "[2022-11-23 15:33:13] Features: 3/5 -- score: 0.9996333690880425[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   55.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    2.4s finished\n",
      "\n",
      "[2022-11-23 15:34:11] Features: 4/5 -- score: 0.9996428208478889[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  49 out of  49 | elapsed:   54.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    3.7s finished\n",
      "\n",
      "[2022-11-23 15:35:10] Features: 5/5 -- score: 0.999633348616291[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current iteration count is 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  53 out of  53 | elapsed:   34.9s finished\n",
      "\n",
      "[2022-11-23 15:35:45] Features: 1/5 -- score: 0.9996242722408137[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  52 out of  52 | elapsed:   46.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "\n",
      "[2022-11-23 15:36:32] Features: 2/5 -- score: 0.9996574557060341[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  51 out of  51 | elapsed:   52.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.3s finished\n",
      "\n",
      "[2022-11-23 15:37:26] Features: 3/5 -- score: 0.9996422726225118[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   51.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    2.4s finished\n",
      "\n",
      "[2022-11-23 15:38:20] Features: 4/5 -- score: 0.9996271877334741[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  49 out of  49 | elapsed:   56.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    2.4s finished\n",
      "\n",
      "[2022-11-23 15:39:23] Features: 4/5 -- score: 0.9996294670843205[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  49 out of  49 | elapsed:   54.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    3.2s finished\n",
      "\n",
      "[2022-11-23 15:40:22] Features: 5/5 -- score: 0.9996425980581366"
     ]
    }
   ],
   "source": [
    "# 3_mlxtend_screening_features\n",
    "# This part is implemented through repeated iterations, which requires a long calculation time. Here we only show the running demo.\n",
    "# The number of iterations corresponds to statistics. This paper carried out a total of 100 iterations, and finally screened the descriptors.\n",
    "data = pd.read_pickle(file_path+'17_filter_threshold_4.pkl')\n",
    "\n",
    "X = data.iloc[:,1:54]\n",
    "y = data.iloc[:,1]\n",
    "y_array = np.array(y)\n",
    "\n",
    "# Calculation parameter settings \n",
    "max_feature_number = 5\n",
    "selection_iteration = 5\n",
    "\n",
    "rfr = RandomForestRegressor()\n",
    "csv_data = []\n",
    "csv_data_one_col = []\n",
    "\n",
    "for selection_iteration_i in range(0,selection_iteration):\n",
    "    print(\"The current iteration count is\",selection_iteration_i+1)\n",
    "    X = shuffle(X.T).T\n",
    "    X_array = np.array(X)\n",
    "    std = StandardScaler()\n",
    "    X_array_std = std.fit_transform(X_array)\n",
    "    sfs = SFS(estimator=rfr,k_features=max_feature_number,forward=True,floating=True,verbose=2,scoring='r2',cv=5)\n",
    "    sfs.fit(X_array_std,y_array)\n",
    "    log_dict = sfs.get_metric_dict()\n",
    "    avg_score_list = []\n",
    "    for max_feature_i in range(1,max_feature_number+1):\n",
    "        avg_score_list.append(log_dict[max_feature_i]['avg_score'])\n",
    "    max_avg_score = max(avg_score_list)\n",
    "    max_score_feature_number = avg_score_list.index(max_avg_score)+1\n",
    "    feature_name_list = []\n",
    "    for feature_name_i in range (0,max_score_feature_number):\n",
    "        feature_name_list.append(X.columns.values.tolist()[int(log_dict[max_score_feature_number]['feature_names'][feature_name_i])-1])\n",
    "        csv_data_one_col.append(X.columns.values.tolist()[int(log_dict[max_score_feature_number]['feature_names'][feature_name_i])-1])\n",
    "    csv_data.append(feature_name_list)\n",
    "\n",
    "csv_data = pd.DataFrame(csv_data)\n",
    "\n",
    "file_demo = '18_descriptor_mlxtend_screening_result.pkl'\n",
    "csv_data.to_pickle(file_path+file_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a3757e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
